{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\uyen\\.conda\\envs\\movielens\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "\n",
    "import lightning as L\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import wikipedia\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.append(os.getcwd())\n",
    "from data import ProcessMovies, ProcessRatings\n",
    "from utils import read_data\n",
    "\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieLensDataset(Dataset):\n",
    "    def __init__(self, train_val='train'):\n",
    "        '''\n",
    "        part: train/val\n",
    "        '''\n",
    "        self.movies, self.users, self.train_ratings, self.val_ratings = self.__feature_engineering()\n",
    "        self.train_val=train_val\n",
    "        \n",
    "    def __len__(self):\n",
    "        if self.train_val == 'train':\n",
    "            return len(self.train_ratings)\n",
    "        else:\n",
    "            return len(self.val_ratings)\n",
    "  \n",
    "    def __getitem__(self, idx):\n",
    "        if self.train_val == 'train':\n",
    "            data = self.train_ratings.iloc[idx]\n",
    "        if self.train_val == 'val':\n",
    "            data = self.val_ratings.iloc[idx]\n",
    "        user_id, movie_id, label = data\n",
    "        print(movie_id)\n",
    "        user_data = self.users[self.users.user_id==user_id].values.squeeze()\n",
    "        movie_data = self.movies[self.movies.movie_id==movie_id].values.squeeze()\n",
    "        return torch.FloatTensor(user_data), torch.FloatTensor(movie_data), torch.FloatTensor([label])\n",
    "    \n",
    "    def __feature_engineering(self):\n",
    "        if not os.path.exists(r'data\\dataset\\movies.pqt'):\n",
    "            ProcessMovies(r'data\\dataset').main()\n",
    "        movies = pd.read_parquet(r'data\\dataset\\movies.pqt')\n",
    "        train_ratings, val_ratings, ratings_ft = ProcessRatings(r'data\\dataset').main()\n",
    "        movies = movies.merge(ratings_ft)\n",
    "        users = read_data('users',table_columns=['user_id','gender','age', 'occupation', 'zipcode'])\n",
    "        users = users.drop('zipcode',axis=1)\n",
    "        users['gender'] = [1.0 if i=='M' else 0.0 for i in users['gender']]\n",
    "        return movies, users, train_ratings, val_ratings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3952\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([23.,  1., 35.,  0.]), tensor([], size=(0, 54)), tensor([1.]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MovieLensDataset('train').__getitem__(2830)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   1,    2,    3, ..., 3947, 3948, 3949], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_list = pd.read_parquet(r'C:\\Users\\uyen\\OneDrive\\NeuralCF\\data\\dataset\\movies.pqt', columns=['movie_id']).values.squeeze()\n",
    "movie_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = read_data('ratings', ['user_id', 'movie_id', 'rating', 'timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3952 in movie_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3950,\n",
       " 3952,\n",
       " 3950,\n",
       " 3951,\n",
       " 3952,\n",
       " 3952,\n",
       " 3950,\n",
       " 3951,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3950,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3951,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3950,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3951,\n",
       " 3952,\n",
       " 3952,\n",
       " 3950,\n",
       " 3952,\n",
       " 3950,\n",
       " 3952,\n",
       " 3951,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3950,\n",
       " 3950,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3950,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3951,\n",
       " 3951,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3950,\n",
       " 3951,\n",
       " 3952,\n",
       " 3951,\n",
       " 3952,\n",
       " 3952,\n",
       " 3951,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3951,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3951,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3950,\n",
       " 3951,\n",
       " 3950,\n",
       " 3951,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3950,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3951,\n",
       " 3952,\n",
       " 3952,\n",
       " 3950,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3950,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3951,\n",
       " 3951,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3950,\n",
       " 3952,\n",
       " 3950,\n",
       " 3952,\n",
       " 3952,\n",
       " 3951,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3951,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3950,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3951,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3951,\n",
       " 3952,\n",
       " 3950,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3950,\n",
       " 3950,\n",
       " 3951,\n",
       " 3952,\n",
       " 3952,\n",
       " 3951,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3950,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3950,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3950,\n",
       " 3951,\n",
       " 3952,\n",
       " 3951,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3950,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3950,\n",
       " 3951,\n",
       " 3952,\n",
       " 3952,\n",
       " 3950,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3951,\n",
       " 3950,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3950,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3951,\n",
       " 3952,\n",
       " 3950,\n",
       " 3951,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3951,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3950,\n",
       " 3952,\n",
       " 3952,\n",
       " 3951,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3951,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3950,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3950,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3950,\n",
       " 3952,\n",
       " 3951,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3950,\n",
       " 3952,\n",
       " 3952,\n",
       " 3950,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3951,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3950,\n",
       " 3952,\n",
       " 3952,\n",
       " 3950,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3950,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3951,\n",
       " 3952,\n",
       " 3952,\n",
       " 3950,\n",
       " 3952,\n",
       " 3952,\n",
       " 3950,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3950,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3950,\n",
       " 3952,\n",
       " 3952,\n",
       " 3950,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3950,\n",
       " 3952,\n",
       " 3951,\n",
       " 3952,\n",
       " 3952,\n",
       " 3951,\n",
       " 3951,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3950,\n",
       " 3952,\n",
       " 3950,\n",
       " 3952,\n",
       " 3952,\n",
       " 3950,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3950,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3951,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3950,\n",
       " 3952,\n",
       " 3952,\n",
       " 3951,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3950,\n",
       " 3952,\n",
       " 3950,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3952,\n",
       " 3950,\n",
       " 3952]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in ratings.movie_id if i not in movie_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "from typing import Any, Optional\n",
    "from lightning.pytorch.utilities.types import STEP_OUTPUT\n",
    "\n",
    "class NCF(L.LightningModule):\n",
    "    \"\"\" Neural Collaborative Filtering (NCF)    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.user_fc_1 = nn.Linear(in_features=4, out_features=16)\n",
    "        self.item_fc_1 = nn.Linear(in_features=54, out_features=16)\n",
    "        self.user_fc_2 = nn.Linear(in_features=16, out_features=1)\n",
    "        self.item_fc_2 = nn.Linear(in_features=16, out_features=1)\n",
    "        self.bilinear = nn.Bilinear(in1_features=16, in2_features=16, out_features=1)\n",
    "        \n",
    "    def forward(self, user_input, item_input):\n",
    "        print(user_input.shape, item_input.shape)\n",
    "        user_vector = nn.ReLU()(self.user_fc_1(user_input))\n",
    "        item_vector = nn.ReLU()(self.item_fc_1(item_input))\n",
    "        user_output = nn.ReLU()(self.user_fc_2(user_vector))\n",
    "        item_output = nn.ReLU()(self.item_fc_2(item_vector))\n",
    "        fusion_output = self.bilinear(user_vector, item_vector)\n",
    "        print((user_output + item_output + fusion_output).shape)\n",
    "        pred = nn.Sigmoid()(user_output + item_output + fusion_output)\n",
    "        return pred\n",
    "    \n",
    "    def loss(self, preds: Tensor, labels: Optional[Tensor] = None) -> Tensor:\n",
    "        print('Pred: ',preds, 'Label: ',labels)\n",
    "        return nn.BCELoss()(preds, labels)\n",
    "\n",
    "    def step(self, batch: Any) -> Tensor:\n",
    "        print('Batch data: ',batch)\n",
    "        user_input, item_input, labels = batch\n",
    "        print('Label from NCF: ', labels)\n",
    "        predicted_labels = self(user_input, item_input)\n",
    "        loss = self.loss(predicted_labels, labels)\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch: Any, batch_idx: int) -> STEP_OUTPUT:\n",
    "        return {\"loss\": self.step(batch)}\n",
    "\n",
    "    def validation_step(self, batch: Any, batch_idx: int) -> STEP_OUTPUT:\n",
    "        return {\"x\": self.step(batch)}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "    \n",
    "    def train_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(MovieLensDataset('train'))\n",
    "\n",
    "    def val_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(MovieLensDataset('val'))\n",
    "\n",
    "model = NCF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name      | Type     | Params\n",
      "---------------------------------------\n",
      "0 | user_fc_1 | Linear   | 80    \n",
      "1 | item_fc_1 | Linear   | 880   \n",
      "2 | user_fc_2 | Linear   | 17    \n",
      "3 | item_fc_2 | Linear   | 17    \n",
      "4 | bilinear  | Bilinear | 257   \n",
      "---------------------------------------\n",
      "1.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.3 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 1/982089 [09:50<161028:29:19,  0.00it/s]\n",
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]Batch data:  [tensor([[ 1.,  0.,  1., 10.]]), tensor([[4.8000e+01, 1.9950e+03, 0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.2793e+00, 1.4268e+01, 6.1766e+00, 9.7921e+00,\n",
      "         7.9547e+00, 5.0468e+00, 5.9323e+00, 7.0207e+00, 7.2744e+00, 5.8935e+00,\n",
      "         4.5633e+00, 8.2570e+00, 3.4874e+00, 6.6938e+00, 5.3376e+00, 6.0674e+00,\n",
      "         2.6647e+00, 4.9364e+00, 5.9470e+00, 5.2435e+00, 3.7170e+00, 3.0763e+00,\n",
      "         6.1591e+00, 4.2392e+00, 4.3145e+00, 3.1931e+00, 3.4200e+00, 5.2906e+00,\n",
      "         5.0871e+00, 4.5525e+00, 7.2238e+00, 8.8252e+00, 2.9764e+00, 3.8200e+02]]), tensor([[1.]])]\n",
      "Label from NCF:  tensor([[1.]])\n",
      "torch.Size([1, 4]) torch.Size([1, 54])\n",
      "torch.Size([1, 1])\n",
      "Pred:  tensor([[0.]]) Label:  tensor([[1.]])\n",
      "Sanity Checking DataLoader 0:  50%|█████     | 1/2 [00:00<?, ?it/s]Batch data:  [tensor([[ 1.,  0.,  1., 10.]]), tensor([[ 1.5660e+03,  1.9970e+03,  0.0000e+00,  1.0000e+00,  1.0000e+00,\n",
      "          1.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.0431e-01,  9.4479e+00,  1.1473e+01,  5.0272e+00,  7.6910e+00,\n",
      "          4.5155e+00,  7.7232e+00,  2.6901e+00,  4.8556e+00,  7.0081e+00,\n",
      "          5.5918e+00,  2.8949e+00,  5.1579e+00,  5.3127e+00,  4.8937e+00,\n",
      "          3.9847e+00,  5.7866e+00,  6.4870e+00,  3.4145e+00,  4.1392e+00,\n",
      "          5.2397e+00,  6.4653e+00,  6.5156e+00,  3.3841e+00,  1.9378e-01,\n",
      "          4.5237e+00,  4.2813e+00,  4.6436e+00,  4.8214e+00,  5.4865e+00,\n",
      "          6.8074e+00,  5.5480e+00,  3.2793e+00,  4.6900e+02]]), tensor([[1.]])]\n",
      "Label from NCF:  tensor([[1.]])\n",
      "torch.Size([1, 4]) torch.Size([1, 54])\n",
      "torch.Size([1, 1])\n",
      "Pred:  tensor([[0.]]) Label:  tensor([[1.]])\n",
      "                                                                            "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\delic\\anaconda3\\envs\\movie_rec\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer(max_epochs=5, devices='auto', enable_progress_bar=True, logger=False)\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finalmlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
